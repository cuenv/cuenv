name: LLMs.txt Evaluation

on:
  push:
    branches: [main]
    paths:
      - "llms.txt"
      - "schema/**/*.cue"
      - "prompts/**/*.prompt.yml"
  pull_request:
    paths:
      - "llms.txt"
      - "schema/**/*.cue"
      - "prompts/**/*.prompt.yml"
  schedule:
    # Run weekly on Sunday at midnight to track baseline
    - cron: "0 0 * * 0"
  workflow_dispatch:

permissions:
  contents: read
  models: read
  pull-requests: write

jobs:
  evaluate:
    name: Evaluate llms.txt Effectiveness
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Install Nix
        uses: DeterminateSystems/nix-installer-action@v16
        with:
          extra-conf: |
            accept-flake-config = true

      - name: Setup Cachix
        uses: cachix/cachix-action@v15
        with:
          name: cuenv
          authToken: "${{ secrets.CACHIX_AUTH_TOKEN }}"
          pushFilter: "(-source$|nixpkgs\\.tar\\.gz$)"

      - name: Build cuenv and generate llms.txt content
        run: |
          nix develop --command cargo build --release
          ./target/release/cuenv --llms > /tmp/llms-full.txt
          echo "Generated llms.txt content ($(wc -l < /tmp/llms-full.txt) lines)"

      - name: Setup GitHub CLI Models Extension
        run: |
          gh extension install github/gh-models || true
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Create results directory
        run: mkdir -p results

      - name: Run Task Generation Evaluation
        run: |
          gh models eval prompts/cuenv-task-generation.prompt.yml \
            --var "llms_context@/tmp/llms-full.txt" \
            --output json > results/task-gen.json 2>&1 || echo '{"error": "eval failed"}' > results/task-gen.json
          cat results/task-gen.json
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Run Env Generation Evaluation
        run: |
          gh models eval prompts/cuenv-env-generation.prompt.yml \
            --var "llms_context@/tmp/llms-full.txt" \
            --output json > results/env-gen.json 2>&1 || echo '{"error": "eval failed"}' > results/env-gen.json
          cat results/env-gen.json
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Run Q&A Evaluation
        run: |
          gh models eval prompts/cuenv-question-answering.prompt.yml \
            --var "llms_context@/tmp/llms-full.txt" \
            --output json > results/qa.json 2>&1 || echo '{"error": "eval failed"}' > results/qa.json
          cat results/qa.json
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Upload Results
        uses: actions/upload-artifact@v4
        with:
          name: eval-results-${{ github.sha }}
          path: results/
          retention-days: 90

      - name: Generate Summary
        id: summary
        run: |
          echo "## LLMs.txt Evaluation Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Commit: ${{ github.sha }}" >> $GITHUB_STEP_SUMMARY
          echo "Date: $(date -u +%Y-%m-%dT%H:%M:%SZ)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Evaluation | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|------------|--------|" >> $GITHUB_STEP_SUMMARY

          for file in results/*.json; do
            name=$(basename "$file" .json)
            if grep -q '"error"' "$file" 2>/dev/null; then
              echo "| $name | :x: Failed |" >> $GITHUB_STEP_SUMMARY
            else
              echo "| $name | :white_check_mark: Completed |" >> $GITHUB_STEP_SUMMARY
            fi
          done

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "See artifacts for detailed results." >> $GITHUB_STEP_SUMMARY

      - name: Comment PR with Results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');

            let summary = '## LLMs.txt Evaluation Results\n\n';
            summary += `**Commit:** \`${context.sha.substring(0, 7)}\`\n\n`;

            const files = ['task-gen', 'env-gen', 'qa'];
            summary += '| Evaluation | Status |\n';
            summary += '|------------|--------|\n';

            for (const file of files) {
              try {
                const content = fs.readFileSync(`results/${file}.json`, 'utf8');
                const hasError = content.includes('"error"');
                const status = hasError ? ':x: Failed' : ':white_check_mark: Completed';
                summary += `| ${file} | ${status} |\n`;
              } catch (e) {
                summary += `| ${file} | :warning: Not found |\n`;
              }
            }

            summary += '\n> See workflow artifacts for detailed evaluation metrics.';

            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: summary
            });
