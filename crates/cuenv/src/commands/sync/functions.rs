//! Sync function implementations.
//!
//! Supports generating:
//! - Ignore files (.gitignore, .dockerignore, etc.) from the `ignore` field
//! - CODEOWNERS file from the `owners` field
//! - Project files from CUE cube templates

use super::super::env_file::find_cue_module_root;
use super::super::owners;
use super::super::{CommandExecutor, convert_engine_error, relative_path_from_root};
use cuengine::ModuleEvalOptions;
use cuenv_core::manifest::{Base, Project};
use cuenv_core::{ModuleEvaluation, Result};
use cuenv_github::GitHubConfigExt;
use cuenv_ignore::{FileStatus, IgnoreFile, IgnoreFiles};
use similar::TextDiff;
use std::collections::{HashMap, HashSet};
use std::path::{Path, PathBuf};
use tracing::instrument;

/// The header added to all cuenv-generated ignore files.
const CUENV_IGNORE_HEADER: &str = "Generated by cuenv - do not edit\nSource: env.cue";

/// Collect file paths from cube config where gitignore is true.
fn collect_cube_gitignore_patterns(manifest: &Project) -> Vec<String> {
    let Some(cube) = &manifest.cube else {
        return Vec::new();
    };

    let mut patterns: Vec<String> = cube
        .files
        .iter()
        .filter(|(_, file)| file.gitignore)
        .map(|(path, _)| path.clone())
        .collect();

    // Sort for deterministic output
    patterns.sort();
    patterns
}

/// Convert Project manifest ignore configuration to `cuenv_ignore::IgnoreFile` configs.
/// Also integrates cube-generated gitignore patterns.
fn convert_project_to_ignore_files(manifest: &Project) -> Vec<IgnoreFile> {
    let mut files = Vec::new();

    // Collect cube gitignore patterns
    let cube_patterns = collect_cube_gitignore_patterns(manifest);

    // Process project-level ignore configurations
    if let Some(ignore) = &manifest.ignore {
        for (tool, value) in ignore {
            let mut patterns: Vec<String> = Vec::new();

            // Add project-level patterns
            let project_patterns: Vec<String> = value.patterns().to_vec();
            if !project_patterns.is_empty() {
                patterns.push("# Project ignores".to_string());
                patterns.extend(project_patterns);
            }

            // For git, also add cube patterns
            if tool == "git" && !cube_patterns.is_empty() {
                if !patterns.is_empty() {
                    patterns.push(String::new()); // Empty line separator
                }
                patterns.push("# Cube-generated files".to_string());
                patterns.extend(cube_patterns.clone());
            }

            if !patterns.is_empty() {
                files.push(
                    IgnoreFile::new(tool)
                        .patterns(patterns)
                        .filename_opt(value.filename())
                        .header(CUENV_IGNORE_HEADER),
                );
            }
        }
    }

    // If there are cube patterns but no git ignore config, create one
    if !cube_patterns.is_empty() {
        let has_git_ignore = manifest
            .ignore
            .as_ref()
            .is_some_and(|i| i.contains_key("git"));

        if !has_git_ignore {
            let mut patterns = vec!["# Cube-generated files".to_string()];
            patterns.extend(cube_patterns);

            files.push(
                IgnoreFile::new("git")
                    .patterns(patterns)
                    .header(CUENV_IGNORE_HEADER),
            );
        }
    }

    files
}

/// Load Project configuration from CUE using module-wide evaluation.
fn load_project_config(
    path: &Path,
    package: &str,
    executor: Option<&CommandExecutor>,
) -> Result<Project> {
    let (instance, _module_root) = load_instance_at_path(path, package, executor)?;
    instance.deserialize()
}

/// Load a CUE instance at the given path using module-wide evaluation.
/// Returns the instance and the module root path.
///
/// When an `executor` is provided, uses its cached module evaluation.
/// Otherwise, falls back to fresh evaluation (legacy behavior).
fn load_instance_at_path(
    path: &Path,
    package: &str,
    executor: Option<&CommandExecutor>,
) -> Result<(cuenv_core::module::Instance, PathBuf)> {
    let target_path = path.canonicalize().map_err(|e| cuenv_core::Error::Io {
        source: e,
        path: Some(path.to_path_buf().into_boxed_path()),
        operation: "canonicalize path".to_string(),
    })?;

    // Use executor's cached module if available
    if let Some(exec) = executor {
        tracing::debug!("Using cached module evaluation from executor");
        let module = exec.get_module(&target_path)?;
        let relative_path = relative_path_from_root(&module.root, &target_path);

        let instance = module.get(&relative_path).ok_or_else(|| {
            cuenv_core::Error::configuration(format!(
                "No CUE instance found at path: {} (relative: {})",
                target_path.display(),
                relative_path.display()
            ))
        })?;

        return Ok((instance.clone(), module.root.clone()));
    }

    // Legacy path: fresh evaluation
    tracing::debug!("Using fresh module evaluation (no executor)");

    let module_root = find_cue_module_root(&target_path).ok_or_else(|| {
        cuenv_core::Error::configuration(format!(
            "No CUE module found (looking for cue.mod/) starting from: {}",
            target_path.display()
        ))
    })?;

    let options = ModuleEvalOptions {
        recursive: true,
        ..Default::default()
    };
    let raw_result = cuengine::evaluate_module(&module_root, package, Some(&options))
        .map_err(convert_engine_error)?;

    let module = ModuleEvaluation::from_raw(
        module_root.clone(),
        raw_result.instances,
        raw_result.projects,
    );

    let relative_path = relative_path_from_root(&module_root, &target_path);
    let instance = module.get(&relative_path).ok_or_else(|| {
        cuenv_core::Error::configuration(format!(
            "No CUE instance found at path: {} (relative: {})",
            target_path.display(),
            relative_path.display()
        ))
    })?;

    Ok((instance.clone(), module_root))
}

/// Execute the sync ignore command.
///
/// Reads the CUE configuration and generates ignore files based on the `ignore` field.
/// Works with both schema.#Base and schema.#Project configurations.
#[instrument(name = "sync_ignore", skip(executor))]
pub async fn execute_sync_ignore(
    path: &str,
    package: &str,
    dry_run: bool,
    check: bool,
    executor: Option<&CommandExecutor>,
) -> Result<String> {
    tracing::info!("Starting sync ignore command");

    // Convert path string to Path
    let dir_path = Path::new(path);

    // Load Project configuration using module-wide evaluation
    tracing::debug!(
        "Loading CUE config for package '{}' at path '{}'",
        package,
        path
    );
    let manifest: Project = load_project_config(dir_path, package, executor)?;

    // Convert to ignore files (includes cube gitignore patterns)
    let files = convert_project_to_ignore_files(&manifest);

    if files.is_empty() {
        tracing::info!("No ignore patterns configured");
        return Ok(
            "No ignore patterns configured. Add an `ignore` field to your env.cue.".to_string(),
        );
    }

    // Check if all files have empty patterns
    let all_empty = files.iter().all(|f| f.patterns_list().is_empty());
    if all_empty {
        return Ok("No ignore files to generate (all pattern lists are empty).".to_string());
    }

    // In check mode, use dry_run and verify files match
    let effective_dry_run = dry_run || check;

    // Generate ignore files using the cuenv-ignore crate
    let result = IgnoreFiles::builder()
        .directory(dir_path)
        .require_git_repo(true)
        .dry_run(effective_dry_run)
        .files(files)
        .generate()
        .map_err(|e| match e {
            cuenv_ignore::Error::NotInGitRepo => {
                cuenv_core::Error::configuration("cuenv sync must be run within a Git repository")
            }
            cuenv_ignore::Error::BareRepository => {
                cuenv_core::Error::configuration("Cannot sync in a bare Git repository")
            }
            cuenv_ignore::Error::OutsideGitRepo => cuenv_core::Error::configuration(
                "Target directory must be within the Git repository",
            ),
            cuenv_ignore::Error::InvalidToolName { name, reason } => {
                cuenv_core::Error::configuration(format!("Invalid tool name '{name}': {reason}"))
            }
            cuenv_ignore::Error::Io(io_err) => cuenv_core::Error::Io {
                source: io_err,
                path: Some(dir_path.to_path_buf().into_boxed_path()),
                operation: "sync ignore files".to_string(),
            },
        })?;

    // In check mode, verify all files are unchanged
    if check {
        let mut out_of_sync = Vec::new();
        for file in &result.files {
            match file.status {
                FileStatus::WouldCreate | FileStatus::WouldUpdate => {
                    out_of_sync.push(file.filename.clone());
                }
                FileStatus::Unchanged | FileStatus::Created | FileStatus::Updated => {}
            }
        }
        if !out_of_sync.is_empty() {
            return Err(cuenv_core::Error::configuration(format!(
                "Ignore files out of sync: {}. Run 'cuenv sync ignore' to update.",
                out_of_sync.join(", ")
            )));
        }
        return Ok("Ignore files are in sync.".to_string());
    }

    // Format output
    let mut output_lines = Vec::new();

    for file in &result.files {
        let status_str = match file.status {
            FileStatus::Created => format!(
                "Created {} ({} patterns)",
                file.filename, file.pattern_count
            ),
            FileStatus::Updated => format!(
                "Updated {} ({} patterns)",
                file.filename, file.pattern_count
            ),
            FileStatus::Unchanged => format!("Unchanged {}", file.filename),
            FileStatus::WouldCreate => format!(
                "Would create {} ({} patterns)",
                file.filename, file.pattern_count
            ),
            FileStatus::WouldUpdate => format!(
                "Would update {} ({} patterns)",
                file.filename, file.pattern_count
            ),
        };
        output_lines.push(status_str);
    }

    if output_lines.is_empty() {
        return Ok("No ignore files to generate (all pattern lists are empty).".to_string());
    }

    let output = output_lines.join("\n");
    tracing::info!("Sync ignore command completed successfully");
    Ok(output)
}

/// Execute the sync codeowners command.
///
/// Reads the CUE configuration and generates CODEOWNERS file based on the `owners` field.
/// When `allow_missing_config` is true, missing owners config will return a message instead of error.
#[allow(dead_code)]
#[instrument(name = "sync_codeowners")]
pub async fn execute_sync_codeowners(
    path: &str,
    package: &str,
    dry_run: bool,
    check: bool,
) -> Result<String> {
    execute_sync_codeowners_inner(path, package, dry_run, check, false).await
}

/// Execute the sync codeowners command with option to allow missing config.
#[allow(dead_code)]
pub async fn execute_sync_codeowners_optional(
    path: &str,
    package: &str,
    dry_run: bool,
    check: bool,
) -> Result<String> {
    execute_sync_codeowners_inner(path, package, dry_run, check, true).await
}

/// Inner implementation that handles the `allow_missing_config` flag.
#[allow(dead_code)]
async fn execute_sync_codeowners_inner(
    path: &str,
    package: &str,
    dry_run: bool,
    check: bool,
    allow_missing_config: bool,
) -> Result<String> {
    tracing::info!("Starting sync codeowners command");

    let result = if check {
        owners::execute_owners_check(path, package, None).await
    } else {
        owners::execute_owners_sync(path, package, dry_run, None).await
    };

    // When called from aggregate sync (allow_missing_config=true), treat missing config as no-op
    match result {
        Ok(output) => Ok(output),
        Err(cuenv_core::Error::Configuration { message, .. })
            if allow_missing_config && message.contains("No 'owners' configuration") =>
        {
            Ok("No owners configuration found. Add an 'owners' section to your env.cue to enable CODEOWNERS sync.".to_string())
        }
        Err(cuenv_core::Error::Configuration { message, .. })
            if allow_missing_config
                && message.contains("No code ownership rules defined") =>
        {
            Ok("No code ownership rules defined.".to_string())
        }
        Err(e) => Err(e),
    }
}

/// Create a synthetic project name from a relative path.
pub fn synthetic_name_from_path(path: &Path) -> String {
    if path == Path::new(".") {
        "[root]".to_string()
    } else {
        path.to_string_lossy().replace('/', "::")
    }
}

/// Execute workspace-wide codeowners sync.
///
/// Aggregates ownership rules from all configs in the CUE module into a single CODEOWNERS file.
/// CODEOWNERS is a single file at repo root, so it must aggregate all configs.
#[instrument(name = "sync_codeowners_workspace", skip(executor))]
pub async fn execute_sync_codeowners_workspace(
    package: &str,
    dry_run: bool,
    check: bool,
    executor: &CommandExecutor,
) -> Result<String> {
    use crate::providers::detect_code_owners_provider;
    use cuenv_codeowners::Rule;
    use cuenv_codeowners::provider::{ProjectOwners, SyncStatus};

    // Find the CUE module root from current directory
    let cwd = std::env::current_dir().map_err(|e| {
        cuenv_core::Error::configuration(format!("Failed to get current directory: {e}"))
    })?;

    // Use cached module from executor (avoids redundant CUE evaluation)
    let module = executor.get_module(&cwd)?;

    // Collect all configs with owners configuration
    let mut project_owners_list = Vec::new();

    // Iterate through ALL instances (both Base and Project) since owners applies to both
    for (path, instance) in &module.instances {
        // Deserialize as Base to access the owners field
        let manifest: Base = match instance.deserialize() {
            Ok(m) => m,
            Err(_) => continue, // Skip instances that can't be deserialized
        };

        let Some(owners) = &manifest.owners else {
            continue; // Skip instances without owners configuration
        };

        // Convert manifest rules to codeowners rules (sorted by order then key)
        let mut rule_entries: Vec<_> = owners.rules.iter().collect();
        rule_entries.sort_by(|a, b| {
            let order_a = a.1.order.unwrap_or(i32::MAX);
            let order_b = b.1.order.unwrap_or(i32::MAX);
            order_a.cmp(&order_b).then_with(|| a.0.cmp(b.0))
        });

        let rules: Vec<Rule> = rule_entries
            .iter()
            .map(|(_key, r)| {
                let mut rule = Rule::new(&r.pattern, r.owners.clone());
                if let Some(desc) = &r.description {
                    rule = rule.description(desc.to_owned());
                }
                if let Some(section) = &r.section {
                    rule = rule.section(section.to_owned());
                }
                rule
            })
            .collect();

        // Use synthetic name from directory path
        let synthetic_name = synthetic_name_from_path(path);
        let proj_owners = ProjectOwners::new(path.clone(), synthetic_name, rules);

        project_owners_list.push(proj_owners);
    }

    if project_owners_list.is_empty() {
        return Ok("No configs with owners configuration found.".to_string());
    }

    // Detect provider based on repo structure
    let provider = detect_code_owners_provider(&module.root);

    if check {
        // Check mode - verify CODEOWNERS is in sync
        let result = provider
            .check(&module.root, &project_owners_list)
            .map_err(|e| cuenv_core::Error::configuration(e.to_string()))?;

        if result.in_sync {
            Ok(format!(
                "CODEOWNERS file is in sync: {}",
                result.path.display()
            ))
        } else if result.actual.is_none() {
            Err(cuenv_core::Error::configuration(format!(
                "CODEOWNERS file not found at {}. Run 'cuenv sync codeowners' to generate it.",
                result.path.display()
            )))
        } else {
            Err(cuenv_core::Error::configuration(format!(
                "CODEOWNERS file is out of sync at {}. Run 'cuenv sync codeowners' to update it.",
                result.path.display()
            )))
        }
    } else {
        use std::fmt::Write;

        // Sync mode - write aggregated CODEOWNERS file
        let result = provider
            .sync(&module.root, &project_owners_list, dry_run)
            .map_err(|e| cuenv_core::Error::configuration(e.to_string()))?;

        let status_msg = match result.status {
            SyncStatus::Created => "Created",
            SyncStatus::Updated => "Updated",
            SyncStatus::Unchanged => "Unchanged",
            SyncStatus::WouldCreate => "Would create",
            SyncStatus::WouldUpdate => "Would update",
        };

        let display_path = result
            .path
            .strip_prefix(&module.root)
            .unwrap_or(&result.path);
        let mut output = format!("{} CODEOWNERS: {}\n", status_msg, display_path.display());

        let _ = writeln!(output, "Aggregated {} config(s)", project_owners_list.len());

        if dry_run {
            output.push_str("\n--- Content ---\n");
            output.push_str(&result.content);
        }

        Ok(output)
    }
}

/// Execute the sync cubes command for a single project.
///
/// Syncs cube-generated files for the project at the specified path.
/// Use `execute_sync_cubes_workspace` for workspace-wide syncing.
///
/// When an `executor` is provided, uses its cached module evaluation.
/// Otherwise, falls back to fresh evaluation (legacy behavior).
#[instrument(name = "sync_cubes", skip(executor))]
pub async fn execute_sync_cubes(
    path: &str,
    package: &str,
    dry_run: bool,
    check: bool,
    diff: bool,
    executor: Option<&CommandExecutor>,
) -> Result<String> {
    tracing::info!("Starting sync cubes command");

    let dir_path = Path::new(path);
    execute_sync_cubes_local(dir_path, package, dry_run, check, diff, executor)
}

/// Sync cubes for the local project only
fn execute_sync_cubes_local(
    dir_path: &Path,
    package: &str,
    dry_run: bool,
    check: bool,
    diff: bool,
    executor: Option<&CommandExecutor>,
) -> Result<String> {
    // Auto-detect package name from env.cue if using default
    let effective_package = if package == "cuenv" {
        detect_package_name(dir_path)?
    } else {
        package.to_string()
    };

    // Use module-wide evaluation (cached if executor provided)
    let manifest: Project = load_project_config(dir_path, &effective_package, executor)?;

    let Some(cube_config) = &manifest.cube else {
        return Ok("No cube configuration found in this project.".to_string());
    };

    sync_cube_files(dir_path, &manifest.name, cube_config, dry_run, check, diff)
}

/// Sync cube files for a single project
fn sync_cube_files(
    project_root: &Path,
    project_name: &str,
    cube_config: &cuenv_core::manifest::CubeConfig,
    dry_run: bool,
    check: bool,
    diff: bool,
) -> Result<String> {
    use cuenv_core::manifest::FileMode;

    let mut output_lines = Vec::new();

    for (file_path, file_def) in &cube_config.files {
        let output_path = project_root.join(file_path);

        match file_def.mode {
            FileMode::Managed => {
                sync_managed_file(
                    &mut output_lines,
                    &output_path,
                    file_path,
                    &file_def.content,
                    dry_run,
                    check,
                    diff,
                )?;
            }
            FileMode::Scaffold => {
                sync_scaffold_file(
                    &mut output_lines,
                    &output_path,
                    file_path,
                    &file_def.content,
                    dry_run,
                    check,
                    diff,
                )?;
            }
        }
    }

    tracing::info!(
        project = project_name,
        files = cube_config.files.len(),
        "Cube sync complete"
    );

    Ok(output_lines.join("\n"))
}

/// Sync a managed cube file (always overwritten to match expected content)
fn sync_managed_file(
    output_lines: &mut Vec<String>,
    output_path: &Path,
    file_path: &str,
    content: &str,
    dry_run: bool,
    check: bool,
    diff: bool,
) -> Result<()> {
    if check || diff {
        if output_path.exists() {
            let contents = std::fs::read_to_string(output_path).unwrap_or_default();
            if contents == content {
                output_lines.push(format!("  OK: {file_path}"));
            } else {
                output_lines.push(format!("  Out of sync: {file_path}"));
                maybe_push_diff(output_lines, diff, file_path, Some(&contents), content);
            }
        } else {
            output_lines.push(format!("  Missing: {file_path}"));
            maybe_push_diff(output_lines, diff, file_path, None, content);
        }
    } else if dry_run {
        if output_path.exists() {
            output_lines.push(format!("  Would update: {file_path}"));
        } else {
            output_lines.push(format!("  Would create: {file_path}"));
        }
    } else {
        write_cube_file(output_path, file_path, content, "managed")?;
        output_lines.push(format!("  Generated: {file_path}"));
    }
    Ok(())
}

/// Sync a scaffold cube file (only created if it doesn't exist)
fn sync_scaffold_file(
    output_lines: &mut Vec<String>,
    output_path: &Path,
    file_path: &str,
    content: &str,
    dry_run: bool,
    check: bool,
    diff: bool,
) -> Result<()> {
    if output_path.exists() {
        if !dry_run && !check {
            tracing::debug!("Skipping {file_path} (scaffold mode, file exists)");
        }
        output_lines.push(format!("  Skipped (exists): {file_path}"));
    } else if check || diff {
        output_lines.push(format!("  Missing scaffold: {file_path}"));
        maybe_push_diff(output_lines, diff, file_path, None, content);
    } else if dry_run {
        output_lines.push(format!("  Would scaffold: {file_path}"));
    } else {
        write_cube_file(output_path, file_path, content, "scaffold")?;
        output_lines.push(format!("  Scaffolded: {file_path}"));
    }
    Ok(())
}

/// Write a cube file to disk, creating parent directories as needed
fn write_cube_file(output_path: &Path, file_path: &str, content: &str, mode: &str) -> Result<()> {
    tracing::debug!(
        file_path = %file_path,
        output_path = %output_path.display(),
        content_len = content.len(),
        "Writing {mode} cube file"
    );
    if let Some(parent) = output_path.parent() {
        std::fs::create_dir_all(parent).map_err(|e| {
            tracing::error!(
                parent = %parent.display(),
                error = %e,
                "Failed to create parent directory"
            );
            cuenv_core::Error::Io {
                source: e,
                path: Some(parent.to_path_buf().into_boxed_path()),
                operation: format!("create parent directory for {mode} file: {file_path}"),
            }
        })?;
    }
    std::fs::write(output_path, content).map_err(|e| {
        tracing::error!(
            output_path = %output_path.display(),
            error = %e,
            "Failed to write {mode} file"
        );
        cuenv_core::Error::Io {
            source: e,
            path: Some(output_path.to_path_buf().into_boxed_path()),
            operation: format!("write {mode} file: {file_path}"),
        }
    })?;
    Ok(())
}

fn maybe_push_diff(
    output_lines: &mut Vec<String>,
    diff: bool,
    file_path: &str,
    existing: Option<&str>,
    expected: &str,
) {
    if !diff {
        return;
    }
    let current = existing.unwrap_or("");
    if current == expected {
        return;
    }
    output_lines.push(format_unified_diff(file_path, current, expected));
}

fn format_unified_diff(path: &str, current: &str, expected: &str) -> String {
    let diff = TextDiff::from_lines(current, expected);
    let from = format!("a/{path}");
    let to = format!("b/{path}");
    diff.unified_diff().header(&from, &to).to_string()
}

/// Detect the CUE package name from env.cue
fn detect_package_name(project_path: &Path) -> Result<String> {
    let env_cue = project_path.join("env.cue");
    if !env_cue.exists() {
        return Ok("cuenv".to_string());
    }

    let content = std::fs::read_to_string(&env_cue)?;
    for line in content.lines().take(10) {
        let trimmed = line.trim();
        if trimmed.starts_with("package ") {
            return Ok(trimmed
                .strip_prefix("package ")
                .unwrap_or("cuenv")
                .trim()
                .to_string());
        }
    }

    Ok("cuenv".to_string())
}

// ============================================================================
// CI Workflow Sync
// ============================================================================

/// Execute the sync ci command for a single project.
///
/// Syncs CI workflow files (GitHub Actions, Buildkite) based on CUE configuration.
#[instrument(name = "sync_ci", skip_all)]
pub async fn execute_sync_ci(
    path: &str,
    _package: &str,
    dry_run: bool,
    check: bool,
    provider: Option<&str>,
    executor: &CommandExecutor,
) -> Result<String> {
    tracing::info!("Starting sync ci command");

    let dir_path = Path::new(path);

    // Get cached module from executor and discover projects before async work
    // (ModuleGuard contains MutexGuard which is not Send)
    let projects = {
        let cwd = std::env::current_dir().map_err(|e| {
            cuenv_core::Error::configuration(format!("Failed to get current directory: {e}"))
        })?;
        let module = executor.get_module(&cwd)?;
        cuenv_ci::discovery::discover_projects_from_module(&module)
    };

    // Determine which providers to sync
    let providers = match provider {
        Some(p) => vec![p.to_string()],
        None => vec!["github".to_string(), "buildkite".to_string()],
    };

    let mut outputs = Vec::new();
    let mut errors: Vec<(String, cuenv_core::Error)> = Vec::new();

    for prov in &providers {
        let result = match prov.as_str() {
            "github" => execute_sync_github(dir_path, dry_run, check, &projects).await,
            "buildkite" => execute_sync_buildkite(dir_path, dry_run, check),
            _ => Err(cuenv_core::Error::configuration(format!(
                "Unsupported CI provider: {prov}. Supported: github, buildkite"
            ))),
        };

        match result {
            Ok(output) if !output.is_empty() => outputs.push(output),
            Ok(_) => {} // Skip empty output (no config for this provider)
            Err(e) => {
                if provider.is_some() {
                    return Err(e);
                }
                tracing::debug!("Skipping {prov}: {e}");
                errors.push((prov.clone(), e));
            }
        }
    }

    if outputs.is_empty() {
        if errors.is_empty() {
            Ok("No CI configuration found.".to_string())
        } else {
            // CI config exists but all providers had errors
            let error_summary: Vec<String> = errors
                .iter()
                .map(|(prov, e)| format!("{prov}: {e}"))
                .collect();
            Ok(format!(
                "CI sync failed for all providers:\n{}",
                error_summary.join("\n")
            ))
        }
    } else {
        Ok(outputs.join("\n"))
    }
}

/// Execute workspace-wide CI sync.
///
/// Syncs CI workflow files for all projects with CI configuration.
#[instrument(name = "sync_ci_workspace", skip_all)]
pub async fn execute_sync_ci_workspace(
    _package: &str,
    dry_run: bool,
    check: bool,
    provider: Option<&str>,
    executor: &CommandExecutor,
) -> Result<String> {
    // Get cached module from executor and discover projects before async work
    // (ModuleGuard contains MutexGuard which is not Send, must be dropped before await)
    let projects = {
        let cwd = std::env::current_dir().map_err(|e| {
            cuenv_core::Error::configuration(format!("Failed to get current directory: {e}"))
        })?;
        let module = executor.get_module(&cwd)?;
        cuenv_ci::discovery::discover_projects_from_module(&module)
    };

    if projects.is_empty() {
        return Ok("No projects with CI configuration found.".to_string());
    }

    let mut outputs = Vec::new();

    for project in &projects {
        let project_path = project.path.parent().map_or_else(
            || Path::new("."),
            |p| {
                if p.as_os_str().is_empty() {
                    Path::new(".")
                } else {
                    p
                }
            },
        );

        let result = execute_sync_ci(
            project_path.to_str().unwrap_or("."),
            "cuenv",
            dry_run,
            check,
            provider,
            executor,
        )
        .await;

        match result {
            Ok(output) if !output.is_empty() => {
                outputs.push(format!("[{}]\n{}", project.config.name, output));
            }
            Ok(_) => {}
            Err(e) => {
                outputs.push(format!("[{}] Error: {}", project.config.name, e));
            }
        }
    }

    if outputs.is_empty() {
        Ok("No CI workflows to sync.".to_string())
    } else {
        Ok(outputs.join("\n\n"))
    }
}

/// Sync GitHub Actions workflow files from CUE configuration.
#[allow(clippy::too_many_lines)]
#[instrument(name = "sync_github", skip_all)]
async fn execute_sync_github(
    _project_path: &Path,
    dry_run: bool,
    check: bool,
    projects: &[cuenv_ci::discovery::DiscoveredCIProject],
) -> Result<String> {
    if projects.is_empty() {
        return Err(cuenv_core::Error::configuration(
            "No cuenv projects found. Ensure env.cue files declare 'package cuenv'",
        ));
    }

    // Generate workflows per-project, per-pipeline
    // Each project with CI config gets its own workflow files
    let mut all_workflows: Vec<(String, String)> = Vec::new();
    for project in projects {
        let Some(ci) = &project.config.ci else {
            continue;
        };
        for pipeline in &ci.pipelines {
            let workflows = generate_github_workflow_for_project(project, pipeline)?;
            all_workflows.extend(workflows);
        }
    }

    if all_workflows.is_empty() {
        return Ok(String::new());
    }

    let workflows_dir = Path::new(".github/workflows");
    let mut output_lines = Vec::new();

    // Check mode: compare generated content with existing files
    if check {
        let mut out_of_sync = Vec::new();
        for (filename, content) in &all_workflows {
            let path = workflows_dir.join(filename);
            if path.exists() {
                let existing =
                    std::fs::read_to_string(&path).map_err(|e| cuenv_core::Error::Io {
                        source: e,
                        path: Some(path.clone().into_boxed_path()),
                        operation: "read workflow file".to_string(),
                    })?;
                if existing != *content {
                    out_of_sync.push(filename.clone());
                }
            } else {
                out_of_sync.push(format!("{filename} (missing)"));
            }
        }
        if !out_of_sync.is_empty() {
            return Err(cuenv_core::Error::configuration(format!(
                "GitHub workflows out of sync: {}. Run 'cuenv sync ci' to update.",
                out_of_sync.join(", ")
            )));
        }
        return Ok(format!(
            "GitHub: {} workflow(s) in sync",
            all_workflows.len()
        ));
    }

    // Dry-run or normal mode
    for (filename, content) in &all_workflows {
        let workflow_path = workflows_dir.join(filename);
        let exists = workflow_path.exists();

        // Check if content matches (skip if unchanged)
        if exists && !dry_run {
            let existing = std::fs::read_to_string(&workflow_path).unwrap_or_default();
            if existing == *content {
                output_lines.push(format!("GitHub: {filename} (unchanged)"));
                continue;
            }
        }

        if dry_run {
            if exists {
                output_lines.push(format!("GitHub: Would update {filename}"));
            } else {
                output_lines.push(format!("GitHub: Would create {filename}"));
            }
        } else {
            // Create directory if needed
            if !workflows_dir.exists() {
                std::fs::create_dir_all(workflows_dir).map_err(|e| cuenv_core::Error::Io {
                    source: e,
                    path: Some(workflows_dir.to_path_buf().into_boxed_path()),
                    operation: "create directory".to_string(),
                })?;
            }

            std::fs::write(&workflow_path, content).map_err(|e| cuenv_core::Error::Io {
                source: e,
                path: Some(workflow_path.clone().into_boxed_path()),
                operation: "write workflow file".to_string(),
            })?;

            if exists {
                output_lines.push(format!("GitHub: Updated {filename}"));
            } else {
                output_lines.push(format!("GitHub: Created {filename}"));
            }
        }
    }

    Ok(output_lines.join("\n"))
}

/// Collected pipeline context from project discovery.
struct PipelineContext {
    is_release: bool,
    github_config: cuenv_github::config::GitHubConfig,
    trigger: cuenv_ci::ir::TriggerCondition,
    project_name: Option<String>,
    environment: Option<String>,
    stages: cuenv_ci::ir::StageConfiguration,
    runtimes: Vec<cuenv_ci::ir::Runtime>,
    tasks: Vec<cuenv_ci::ir::Task>,
    /// Original pipeline tasks (with matrix/artifacts/params info)
    pipeline_tasks: Vec<cuenv_core::ci::PipelineTask>,
}

/// Check if any pipeline tasks have matrix configurations.
fn has_matrix_tasks(pipeline_tasks: &[cuenv_core::ci::PipelineTask]) -> bool {
    pipeline_tasks
        .iter()
        .any(cuenv_core::ci::PipelineTask::is_matrix)
}

/// Generate GitHub workflow files for a single project and pipeline.
fn generate_github_workflow_for_project(
    project: &cuenv_ci::discovery::DiscoveredCIProject,
    pipeline: &cuenv_core::ci::Pipeline,
) -> Result<Vec<(String, String)>> {
    let ctx = build_project_pipeline_context(project, pipeline)?;

    // Check for matrix tasks (these need special handling)
    if has_matrix_tasks(&ctx.pipeline_tasks) {
        return emit_matrix_workflow(&pipeline.name, &ctx);
    }

    if ctx.is_release {
        return emit_release_workflow(&pipeline.name, &ctx);
    }

    if ctx.tasks.is_empty() {
        return Ok(Vec::new());
    }

    emit_standard_workflow(&pipeline.name, &ctx)
}

/// Build pipeline context for a single project and pipeline.
fn build_project_pipeline_context(
    project: &cuenv_ci::discovery::DiscoveredCIProject,
    pipeline: &cuenv_core::ci::Pipeline,
) -> Result<PipelineContext> {
    use cuenv_ci::compiler::{Compiler, CompilerOptions};

    let ci = project
        .config
        .ci
        .as_ref()
        .ok_or_else(|| cuenv_core::Error::configuration("Project has no CI configuration"))?;

    // Detect release pipelines by checking if they have release event triggers
    let is_release = pipeline.when.as_ref().is_some_and(|w| w.release.is_some());

    let options = CompilerOptions {
        pipeline: Some(pipeline.clone()),
        ..Default::default()
    };
    let compiler = Compiler::with_options(project.config.clone(), options);
    let ir = compiler
        .compile()
        .map_err(|e| cuenv_core::Error::configuration(format!("Failed to compile project: {e}")))?;

    // Extract task names from pipeline tasks (which can be simple strings or matrix tasks)
    let pipeline_task_names: Vec<String> = pipeline
        .tasks
        .iter()
        .map(|t| t.task_name().to_string())
        .collect();
    let tasks = cuenv_ci::pipeline::filter_tasks(&pipeline_task_names, ir.tasks);

    Ok(PipelineContext {
        is_release,
        github_config: ci.github_config_for_pipeline(&pipeline.name),
        trigger: build_github_trigger_condition(pipeline, ci),
        project_name: Some(project.config.name.clone()),
        environment: pipeline.environment.clone(),
        stages: ir.stages,
        runtimes: ir.runtimes,
        tasks,
        pipeline_tasks: pipeline.tasks.clone(),
    })
}

/// Emit a release workflow using the `ReleaseWorkflowBuilder`.
fn emit_release_workflow(
    pipeline_name: &str,
    ctx: &PipelineContext,
) -> Result<Vec<(String, String)>> {
    use cuenv_ci::ir::{IntermediateRepresentation, PipelineMetadata};
    use cuenv_github::workflow::{GitHubActionsEmitter, ReleaseWorkflowBuilder};

    let ir = IntermediateRepresentation {
        version: "1.4".to_string(),
        pipeline: PipelineMetadata {
            name: pipeline_name.to_string(),
            environment: ctx.environment.clone(),
            requires_onepassword: false,
            project_name: ctx.project_name.clone(),
            trigger: Some(ctx.trigger.clone()),
            pipeline_tasks: vec![],
        },
        runtimes: ctx.runtimes.clone(),
        stages: ctx.stages.clone(),
        tasks: Vec::new(),
    };

    let emitter = GitHubActionsEmitter::from_config(&ctx.github_config).with_nix();
    let workflow = ReleaseWorkflowBuilder::new(emitter).build(&ir);

    let workflow_name = match &ir.pipeline.project_name {
        Some(project) => format!("{project}-{}", ir.pipeline.name),
        None => ir.pipeline.name.clone(),
    };
    let filename = format!("{}.yml", sanitize_workflow_name(&workflow_name));

    let yaml = workflow.to_yaml().map_err(|e| {
        cuenv_core::Error::configuration(format!("Failed to serialize workflow: {e}"))
    })?;

    Ok(vec![(filename, yaml)])
}

/// Emit a standard workflow using the `GitHubActionsEmitter`.
fn emit_standard_workflow(
    pipeline_name: &str,
    ctx: &PipelineContext,
) -> Result<Vec<(String, String)>> {
    use cuenv_ci::ir::{IntermediateRepresentation, PipelineMetadata};
    use cuenv_github::workflow::GitHubActionsEmitter;

    let ir = IntermediateRepresentation {
        version: "1.4".to_string(),
        pipeline: PipelineMetadata {
            name: pipeline_name.to_string(),
            environment: ctx.environment.clone(),
            requires_onepassword: false,
            project_name: ctx.project_name.clone(),
            trigger: Some(ctx.trigger.clone()),
            pipeline_tasks: vec![],
        },
        runtimes: ctx.runtimes.clone(),
        stages: ctx.stages.clone(),
        tasks: ctx.tasks.clone(),
    };

    let emitter = GitHubActionsEmitter::from_config(&ctx.github_config).with_nix();
    let workflows = emitter.emit_workflows(&ir).map_err(|e| {
        cuenv_core::Error::configuration(format!("Failed to emit GitHub workflow: {e}"))
    })?;

    Ok(workflows.into_iter().collect())
}

/// Build jobs from expanded pipeline tasks, tracking artifact sources.
///
/// Uses `GitHubActionsEmitter` methods to build jobs, converting `PipelineTask`
/// info to IR `Task` fields as needed.
fn build_pipeline_jobs(
    expanded_tasks: &[cuenv_core::ci::PipelineTask],
    ctx: &PipelineContext,
    emitter: &cuenv_github::workflow::GitHubActionsEmitter,
) -> indexmap::IndexMap<String, cuenv_github::workflow::schema::Job> {
    use indexmap::IndexMap;

    let mut jobs = IndexMap::new();
    let mut artifact_source_jobs: HashSet<String> = HashSet::new();
    let mut processed_task_names: HashSet<String> = HashSet::new();

    for pipeline_task in expanded_tasks {
        let task_name = pipeline_task.task_name();
        processed_task_names.insert(task_name.to_string());
        let job_id = task_name.replace(['.', ' '], "-");

        match pipeline_task {
            cuenv_core::ci::PipelineTask::Simple(_) => {
                if let Some(ir_task) = ctx.tasks.iter().find(|t| t.id == task_name) {
                    // Use emitter method directly
                    let mut job =
                        emitter.build_simple_job(ir_task, &ctx.stages, ctx.environment.as_ref());
                    job.needs = ir_task
                        .depends_on
                        .iter()
                        .map(|dep| dep.replace(['.', ' '], "-"))
                        .collect();
                    jobs.insert(job_id, job);
                }
            }
            cuenv_core::ci::PipelineTask::Matrix(matrix_task) => {
                if matrix_task.matrix.is_empty() {
                    // Artifact aggregation task: create a synthetic IR Task with artifact_downloads
                    let ir_task = ctx.tasks.iter().find(|t| t.id == task_name);
                    let mut seen: HashSet<String> = artifact_source_jobs.clone();
                    let mut combined_needs: Vec<String> =
                        artifact_source_jobs.iter().cloned().collect();

                    if let Some(ir_task) = ir_task {
                        for dep in &ir_task.depends_on {
                            let dep_job_id = dep.replace(['.', ' '], "-");
                            if seen.insert(dep_job_id.clone()) {
                                combined_needs.push(dep_job_id);
                            }
                        }
                    }

                    // Create synthetic IR Task with artifact_downloads and params
                    let synthetic_task = create_synthetic_aggregation_task(task_name, matrix_task);
                    let job = emitter.build_artifact_aggregation_job(
                        &synthetic_task,
                        &ctx.stages,
                        ctx.environment.as_ref(),
                        &combined_needs,
                    );
                    jobs.insert(job_id, job);
                } else {
                    // Matrix expansion task: create a synthetic IR Task with matrix config
                    let synthetic_task = create_synthetic_matrix_task(task_name, matrix_task);
                    let arch_runners = ctx
                        .github_config
                        .runners
                        .as_ref()
                        .and_then(|r| r.arch.clone());

                    let expanded_jobs = emitter.build_matrix_jobs(
                        &synthetic_task,
                        &ctx.stages,
                        ctx.environment.as_ref(),
                        arch_runners.as_ref(),
                        &[],
                    );

                    for (id, job) in expanded_jobs {
                        artifact_source_jobs.insert(id.clone());
                        jobs.insert(id, job);
                    }
                }
            }
        }
    }

    // Add transitive dependencies not in pipeline tasks
    for ir_task in &ctx.tasks {
        // Skip if this task was explicitly in the pipeline (including as matrix task)
        if processed_task_names.contains(&ir_task.id) {
            continue;
        }

        let job_id = ir_task.id.replace(['.', ' '], "-");
        if jobs.contains_key(&job_id) {
            continue;
        }

        // Use emitter method directly
        let mut job = emitter.build_simple_job(ir_task, &ctx.stages, ctx.environment.as_ref());
        job.needs = ir_task
            .depends_on
            .iter()
            .map(|dep| dep.replace(['.', ' '], "-"))
            .collect();
        jobs.insert(job_id, job);
    }

    jobs
}

/// Create a synthetic IR Task for artifact aggregation from a `MatrixTask`.
///
/// Converts `MatrixTask.artifacts` to IR `Task.artifact_downloads` and
/// `MatrixTask.params` to IR `Task.params`.
fn create_synthetic_aggregation_task(
    task_name: &str,
    matrix_task: &cuenv_core::ci::MatrixTask,
) -> cuenv_ci::ir::Task {
    use cuenv_ci::ir::{ArtifactDownload, CachePolicy, Task};

    let artifact_downloads = matrix_task
        .artifacts
        .as_ref()
        .map(|artifacts| {
            artifacts
                .iter()
                .map(|a| ArtifactDownload {
                    name: a.from.replace('.', "-"),
                    path: a.to.clone(),
                    filter: String::new(),
                })
                .collect()
        })
        .unwrap_or_default();

    let params = matrix_task.params.clone().unwrap_or_default();

    Task {
        id: task_name.to_string(),
        runtime: None,
        command: vec![],
        shell: false,
        env: HashMap::new(),
        secrets: HashMap::new(),
        resources: None,
        concurrency_group: None,
        inputs: vec![],
        outputs: vec![],
        depends_on: vec![],
        cache_policy: CachePolicy::Normal,
        deployment: false,
        manual_approval: false,
        matrix: None,
        artifact_downloads,
        params,
    }
}

/// Create a synthetic IR Task for matrix expansion from a `MatrixTask`.
///
/// Converts `MatrixTask.matrix` to IR `Task.matrix`.
fn create_synthetic_matrix_task(
    task_name: &str,
    matrix_task: &cuenv_core::ci::MatrixTask,
) -> cuenv_ci::ir::Task {
    use cuenv_ci::ir::{CachePolicy, MatrixConfig, Task};

    let matrix = MatrixConfig {
        dimensions: matrix_task.matrix.clone(),
        exclude: vec![],
        include: vec![],
        max_parallel: 0,
        fail_fast: true,
    };

    Task {
        id: task_name.to_string(),
        runtime: None,
        command: vec![],
        shell: false,
        env: HashMap::new(),
        secrets: HashMap::new(),
        resources: None,
        concurrency_group: None,
        inputs: vec![],
        outputs: vec![],
        depends_on: vec![],
        cache_policy: CachePolicy::Normal,
        deployment: false,
        manual_approval: false,
        matrix: Some(matrix),
        artifact_downloads: vec![],
        params: HashMap::new(),
    }
}

/// Emit a workflow with matrix expansion for tasks that have matrix configurations.
fn emit_matrix_workflow(
    pipeline_name: &str,
    ctx: &PipelineContext,
) -> Result<Vec<(String, String)>> {
    use cuenv_github::workflow::GitHubActionsEmitter;
    use cuenv_github::workflow::schema::{Concurrency, PermissionLevel, Permissions, Workflow};

    let workflow_name = match &ctx.project_name {
        Some(project) => format!("{project}-{pipeline_name}"),
        None => pipeline_name.to_string(),
    };

    let emitter = GitHubActionsEmitter::from_config(&ctx.github_config).with_nix();

    let explicit_task_names: HashSet<String> = ctx
        .pipeline_tasks
        .iter()
        .map(|pt| pt.task_name().to_string())
        .collect();

    let expanded_tasks = cuenv_ci::pipeline::expand_task_groups(
        &ctx.pipeline_tasks,
        &ctx.tasks,
        &explicit_task_names,
    );

    let jobs = build_pipeline_jobs(&expanded_tasks, ctx, &emitter);

    let workflow = Workflow {
        name: workflow_name.clone(),
        on: build_workflow_triggers(&ctx.trigger, &emitter),
        concurrency: Some(Concurrency {
            group: "${{ github.workflow }}-${{ github.head_ref || github.ref }}".to_string(),
            cancel_in_progress: Some(true),
        }),
        permissions: Some(Permissions {
            contents: Some(PermissionLevel::Write),
            id_token: Some(PermissionLevel::Write),
            ..Default::default()
        }),
        env: indexmap::IndexMap::new(),
        jobs,
    };

    let filename = format!("{}.yml", sanitize_workflow_name(&workflow_name));
    let yaml = workflow.to_yaml().map_err(|e| {
        cuenv_core::Error::configuration(format!("Failed to serialize workflow: {e}"))
    })?;

    Ok(vec![(filename, yaml)])
}

/// Build workflow triggers from the trigger condition.
fn build_workflow_triggers(
    trigger: &cuenv_ci::ir::TriggerCondition,
    _emitter: &cuenv_github::workflow::GitHubActionsEmitter,
) -> cuenv_github::workflow::schema::WorkflowTriggers {
    use cuenv_github::workflow::schema::{
        PullRequestTrigger, PushTrigger, ReleaseTrigger, ScheduleTrigger, WorkflowDispatchTrigger,
        WorkflowInput, WorkflowTriggers,
    };

    let push = if trigger.branches.is_empty() {
        None
    } else {
        Some(PushTrigger {
            branches: trigger.branches.clone(),
            paths: trigger.paths.clone(),
            paths_ignore: trigger.paths_ignore.clone(),
            ..Default::default()
        })
    };

    let pull_request = if trigger.pull_request == Some(true) {
        Some(PullRequestTrigger {
            branches: trigger.branches.clone(),
            paths: trigger.paths.clone(),
            paths_ignore: trigger.paths_ignore.clone(),
            ..Default::default()
        })
    } else {
        None
    };

    let release = if trigger.release.is_empty() {
        None
    } else {
        Some(ReleaseTrigger {
            types: trigger.release.clone(),
        })
    };

    let schedule = if trigger.scheduled.is_empty() {
        None
    } else {
        Some(
            trigger
                .scheduled
                .iter()
                .map(|cron| ScheduleTrigger { cron: cron.clone() })
                .collect(),
        )
    };

    let workflow_dispatch = trigger.manual.as_ref().and_then(|m| {
        if !m.enabled && m.inputs.is_empty() {
            return None;
        }
        Some(WorkflowDispatchTrigger {
            inputs: m
                .inputs
                .iter()
                .map(|(k, v)| {
                    (
                        k.clone(),
                        WorkflowInput {
                            description: v.description.clone(),
                            required: Some(v.required),
                            default: v.default.clone(),
                            input_type: v.input_type.clone(),
                            options: if v.options.is_empty() {
                                None
                            } else {
                                Some(v.options.clone())
                            },
                        },
                    )
                })
                .collect(),
        })
    });

    WorkflowTriggers {
        push,
        pull_request,
        release,
        workflow_dispatch,
        schedule,
    }
}

/// Sanitize a workflow name for use as a filename.
fn sanitize_workflow_name(name: &str) -> String {
    name.to_lowercase()
        .replace(' ', "-")
        .chars()
        .filter(|c| c.is_alphanumeric() || *c == '-' || *c == '_')
        .collect()
}

/// Build GitHub Actions trigger condition from pipeline config.
fn build_github_trigger_condition(
    pipeline: &cuenv_core::ci::Pipeline,
    ci_config: &cuenv_core::ci::CI,
) -> cuenv_ci::ir::TriggerCondition {
    use cuenv_ci::ir::{ManualTriggerConfig, TriggerCondition, WorkflowDispatchInputDef};
    use cuenv_core::ci::ManualTrigger;

    let when = pipeline.when.as_ref();

    let branches = when
        .and_then(|w| w.branch.as_ref())
        .map(cuenv_core::ci::StringOrVec::to_vec)
        .unwrap_or_default();

    let pull_request = when.and_then(|w| w.pull_request);

    let scheduled = when
        .and_then(|w| w.scheduled.as_ref())
        .map(cuenv_core::ci::StringOrVec::to_vec)
        .unwrap_or_default();

    let release = when.and_then(|w| w.release.clone()).unwrap_or_default();

    let manual = when.and_then(|w| w.manual.as_ref()).map(|m| match m {
        ManualTrigger::Enabled(enabled) => ManualTriggerConfig {
            enabled: *enabled,
            inputs: std::collections::HashMap::new(),
        },
        ManualTrigger::WithInputs(inputs) => ManualTriggerConfig {
            enabled: true,
            inputs: inputs
                .iter()
                .map(|(k, v)| {
                    (
                        k.clone(),
                        WorkflowDispatchInputDef {
                            description: v.description.clone(),
                            required: v.required.unwrap_or(false),
                            default: v.default.clone(),
                            input_type: v.input_type.clone(),
                            options: v.options.clone().unwrap_or_default(),
                        },
                    )
                })
                .collect(),
        },
    });

    let paths_ignore = ci_config
        .github_config_for_pipeline(&pipeline.name)
        .paths_ignore
        .unwrap_or_default();

    TriggerCondition {
        branches,
        pull_request,
        scheduled,
        release,
        manual,
        paths: Vec::new(),
        paths_ignore,
    }
}

/// Sync Buildkite bootstrap pipeline file.
#[instrument(name = "sync_buildkite", skip_all)]
fn execute_sync_buildkite(_project_path: &Path, dry_run: bool, check: bool) -> Result<String> {
    // Note: Using --dynamic instead of --format for the new CLI
    let pipeline_content = r#"# Buildkite bootstrap pipeline for cuenv
# This installs Nix, builds cuenv, then generates a dynamic pipeline
steps:
  - label: ":nix: Install Nix"
    key: install-nix
    command: |
      curl --proto '=https' --tlsv1.2 -sSf -L https://install.determinate.systems/nix | sh -s -- install linux --no-confirm --init none
      . /nix/var/nix/profiles/default/etc/profile.d/nix-daemon.sh
      nix --version

  - label: ":package: Build cuenv"
    key: build-cuenv
    depends_on: install-nix
    command: |
      . /nix/var/nix/profiles/default/etc/profile.d/nix-daemon.sh
      nix build .#cuenv --accept-flake-config
      echo "$(pwd)/result/bin" >> "$BUILDKITE_ENV_FILE"

  - label: ":pipeline: Generate Pipeline"
    depends_on: build-cuenv
    command: cuenv ci --dynamic buildkite | buildkite-agent pipeline upload
"#;

    let buildkite_dir = Path::new(".buildkite");
    let pipeline_path = buildkite_dir.join("pipeline.yml");

    // Check mode
    if check {
        if pipeline_path.exists() {
            let existing = std::fs::read_to_string(&pipeline_path).unwrap_or_default();
            if existing == pipeline_content {
                return Ok("Buildkite: pipeline.yml in sync".to_string());
            }
            return Err(cuenv_core::Error::configuration(
                "Buildkite pipeline.yml out of sync. Run 'cuenv sync ci --provider buildkite' to update.",
            ));
        }
        return Err(cuenv_core::Error::configuration(
            "Buildkite pipeline.yml missing. Run 'cuenv sync ci --provider buildkite' to create.",
        ));
    }

    let exists = pipeline_path.exists();

    // Check if file exists and matches (skip if unchanged)
    if exists && !dry_run {
        let existing = std::fs::read_to_string(&pipeline_path).unwrap_or_default();
        if existing == pipeline_content {
            return Ok("Buildkite: pipeline.yml (unchanged)".to_string());
        }
    }

    // Dry-run mode
    if dry_run {
        if exists {
            return Ok("Buildkite: Would update pipeline.yml".to_string());
        }
        return Ok("Buildkite: Would create pipeline.yml".to_string());
    }

    // Create directory if needed
    if !buildkite_dir.exists() {
        std::fs::create_dir_all(buildkite_dir).map_err(|e| cuenv_core::Error::Io {
            source: e,
            path: Some(buildkite_dir.to_path_buf().into_boxed_path()),
            operation: "create directory".to_string(),
        })?;
    }

    // Write file
    std::fs::write(&pipeline_path, pipeline_content).map_err(|e| cuenv_core::Error::Io {
        source: e,
        path: Some(pipeline_path.clone().into_boxed_path()),
        operation: "write pipeline file".to_string(),
    })?;

    if exists {
        Ok("Buildkite: Updated pipeline.yml".to_string())
    } else {
        Ok("Buildkite: Created pipeline.yml".to_string())
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use cuenv_core::manifest::{CubeConfig, IgnoreEntry, IgnoreValue, ProjectFile};
    use std::collections::HashMap;

    #[test]
    fn test_convert_to_ignore_files_empty() {
        let manifest = Project::new("test");
        let files = convert_project_to_ignore_files(&manifest);
        assert!(files.is_empty());
    }

    #[test]
    fn test_convert_to_ignore_files_simple_patterns() {
        let mut manifest = Project::new("test");
        let mut ignore = HashMap::new();
        ignore.insert(
            "git".to_string(),
            IgnoreValue::Patterns(vec!["node_modules/".to_string(), ".env".to_string()]),
        );
        manifest.ignore = Some(ignore);

        let files = convert_project_to_ignore_files(&manifest);
        assert_eq!(files.len(), 1);
        assert_eq!(files[0].tool(), "git");
        // Patterns now include section comment
        assert_eq!(
            files[0].patterns_list(),
            &["# Project ignores", "node_modules/", ".env"]
        );
        assert_eq!(files[0].output_filename(), ".gitignore");
    }

    #[test]
    fn test_convert_to_ignore_files_extended_with_filename() {
        let mut manifest = Project::new("test");
        let mut ignore = HashMap::new();
        ignore.insert(
            "custom".to_string(),
            IgnoreValue::Extended(IgnoreEntry {
                patterns: vec!["*.tmp".to_string()],
                filename: Some(".myignore".to_string()),
            }),
        );
        manifest.ignore = Some(ignore);

        let files = convert_project_to_ignore_files(&manifest);
        assert_eq!(files.len(), 1);
        assert_eq!(files[0].tool(), "custom");
        // Patterns now include section comment
        assert_eq!(files[0].patterns_list(), &["# Project ignores", "*.tmp"]);
        assert_eq!(files[0].output_filename(), ".myignore");
    }

    #[test]
    fn test_convert_to_ignore_files_has_cuenv_header() {
        let mut manifest = Project::new("test");
        let mut ignore = HashMap::new();
        ignore.insert(
            "git".to_string(),
            IgnoreValue::Patterns(vec!["*.log".to_string()]),
        );
        manifest.ignore = Some(ignore);

        let files = convert_project_to_ignore_files(&manifest);
        let content = files[0].generate();

        assert!(content.contains("# Generated by cuenv"));
        assert!(content.contains("# Source: env.cue"));
    }

    // ============================================================================
    // Cube Gitignore Pattern Tests
    // ============================================================================

    #[test]
    fn test_collect_cube_gitignore_patterns_empty() {
        let manifest = Project::new("test");
        let patterns = collect_cube_gitignore_patterns(&manifest);
        assert!(patterns.is_empty());
    }

    #[test]
    fn test_collect_cube_gitignore_patterns_with_gitignore_true() {
        use cuenv_core::manifest::{FileMode, FormatConfig};

        let mut manifest = Project::new("test");
        let mut files = HashMap::new();
        files.insert(
            "dist/generated.js".to_string(),
            ProjectFile {
                content: "// generated".to_string(),
                language: "javascript".to_string(),
                mode: FileMode::default(),
                format: FormatConfig::default(),
                gitignore: true,
            },
        );
        files.insert(
            "src/main.ts".to_string(),
            ProjectFile {
                content: "// source".to_string(),
                language: "typescript".to_string(),
                mode: FileMode::default(),
                format: FormatConfig::default(),
                gitignore: false, // Should not be included
            },
        );
        manifest.cube = Some(CubeConfig {
            files,
            context: serde_json::Value::Null,
        });

        let patterns = collect_cube_gitignore_patterns(&manifest);
        assert_eq!(patterns.len(), 1);
        assert_eq!(patterns[0], "dist/generated.js");
    }

    #[test]
    fn test_collect_cube_gitignore_patterns_sorted() {
        use cuenv_core::manifest::{FileMode, FormatConfig};

        let mut manifest = Project::new("test");
        let mut files = HashMap::new();
        files.insert(
            "z-file.js".to_string(),
            ProjectFile {
                content: String::new(),
                language: "javascript".to_string(),
                mode: FileMode::default(),
                format: FormatConfig::default(),
                gitignore: true,
            },
        );
        files.insert(
            "a-file.js".to_string(),
            ProjectFile {
                content: String::new(),
                language: "javascript".to_string(),
                mode: FileMode::default(),
                format: FormatConfig::default(),
                gitignore: true,
            },
        );
        manifest.cube = Some(CubeConfig {
            files,
            context: serde_json::Value::Null,
        });

        let patterns = collect_cube_gitignore_patterns(&manifest);
        assert_eq!(patterns, vec!["a-file.js", "z-file.js"]);
    }

    #[test]
    fn test_convert_to_ignore_files_with_cube_patterns_only() {
        use cuenv_core::manifest::{FileMode, FormatConfig};

        let mut manifest = Project::new("test");
        let mut files = HashMap::new();
        files.insert(
            "dist/bundle.js".to_string(),
            ProjectFile {
                content: String::new(),
                language: "javascript".to_string(),
                mode: FileMode::default(),
                format: FormatConfig::default(),
                gitignore: true,
            },
        );
        manifest.cube = Some(CubeConfig {
            files,
            context: serde_json::Value::Null,
        });

        let ignore_files = convert_project_to_ignore_files(&manifest);
        assert_eq!(ignore_files.len(), 1);
        assert_eq!(ignore_files[0].tool(), "git");
        assert_eq!(
            ignore_files[0].patterns_list(),
            &["# Cube-generated files", "dist/bundle.js"]
        );
    }

    #[test]
    fn test_convert_to_ignore_files_with_both_project_and_cube_patterns() {
        use cuenv_core::manifest::{FileMode, FormatConfig};

        let mut manifest = Project::new("test");

        // Add project-level git ignores
        let mut ignore = HashMap::new();
        ignore.insert(
            "git".to_string(),
            IgnoreValue::Patterns(vec!["node_modules/".to_string()]),
        );
        manifest.ignore = Some(ignore);

        // Add cube files with gitignore: true
        let mut files = HashMap::new();
        files.insert(
            "dist/bundle.js".to_string(),
            ProjectFile {
                content: String::new(),
                language: "javascript".to_string(),
                mode: FileMode::default(),
                format: FormatConfig::default(),
                gitignore: true,
            },
        );
        manifest.cube = Some(CubeConfig {
            files,
            context: serde_json::Value::Null,
        });

        let ignore_files = convert_project_to_ignore_files(&manifest);
        assert_eq!(ignore_files.len(), 1);
        assert_eq!(ignore_files[0].tool(), "git");

        let patterns = ignore_files[0].patterns_list();
        assert!(patterns.contains(&"# Project ignores".to_string()));
        assert!(patterns.contains(&"node_modules/".to_string()));
        assert!(patterns.contains(&"# Cube-generated files".to_string()));
        assert!(patterns.contains(&"dist/bundle.js".to_string()));
    }

    #[test]
    fn test_cube_patterns_not_added_to_non_git_ignores() {
        use cuenv_core::manifest::{FileMode, FormatConfig};

        let mut manifest = Project::new("test");

        // Add docker ignores (not git)
        let mut ignore = HashMap::new();
        ignore.insert(
            "docker".to_string(),
            IgnoreValue::Patterns(vec!["node_modules/".to_string()]),
        );
        manifest.ignore = Some(ignore);

        // Add cube files with gitignore: true
        let mut files = HashMap::new();
        files.insert(
            "dist/bundle.js".to_string(),
            ProjectFile {
                content: String::new(),
                language: "javascript".to_string(),
                mode: FileMode::default(),
                format: FormatConfig::default(),
                gitignore: true,
            },
        );
        manifest.cube = Some(CubeConfig {
            files,
            context: serde_json::Value::Null,
        });

        let ignore_files = convert_project_to_ignore_files(&manifest);
        // Should have 2 files: docker (without cube patterns) and git (with cube patterns only)
        assert_eq!(ignore_files.len(), 2);

        let docker_file = ignore_files.iter().find(|f| f.tool() == "docker").unwrap();
        let git_file = ignore_files.iter().find(|f| f.tool() == "git").unwrap();

        // Docker should not have cube patterns
        assert!(
            !docker_file
                .patterns_list()
                .contains(&"dist/bundle.js".to_string())
        );

        // Git should have cube patterns
        assert!(
            git_file
                .patterns_list()
                .contains(&"dist/bundle.js".to_string())
        );
    }
}
