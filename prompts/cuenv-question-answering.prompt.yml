name: cuenv Q&A
description: Test if LLM can accurately answer cuenv questions using llms.txt context
model: openai/gpt-5
modelParameters:
  temperature: 0.2
  max_tokens: 256
messages:
  - role: system
    content: |
      Answer questions about cuenv accurately and concisely using only the provided documentation.
      If the answer is not in the documentation, say so.

      Documentation:
      {{llms_context}}
  - role: user
    content: "{{question}}"
testData:
  - question: "How do I run tasks in parallel with cuenv?"
    expected: "Use object syntax with named keys in a task group - each key runs in parallel. Arrays run sequentially."
  - question: "How are secrets handled in cuenv?"
    expected: "Secrets are resolved at runtime from providers like 1Password, AWS, or Vault. They are never written to disk, never exported to shell history, and are redacted from logs."
  - question: "What is the difference between cuenv exec and cuenv task?"
    expected: "cuenv exec runs any command with validated environment and secrets. cuenv task runs named tasks defined in CUE with dependencies, parallelism, and caching."
  - question: "How do I define task dependencies in cuenv?"
    expected: "Use the dependsOn field in a task definition with an array of task names that must complete first."
  - question: "What file do I create to configure cuenv?"
    expected: "Create an env.cue file with package cuenv, import the schema, and define your env and tasks."
evaluators:
  - name: Relevance
    uses: github/relevance
  - name: Groundedness
    uses: github/groundedness
  - name: Coherence
    uses: github/coherence
